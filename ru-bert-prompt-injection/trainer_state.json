{
  "best_global_step": 3780,
  "best_metric": 0.18753916025161743,
  "best_model_checkpoint": "/kaggle/working/results/checkpoint-3780",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 12600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07936507936507936,
      "grad_norm": 2.7925209999084473,
      "learning_rate": 4.960714285714286e-05,
      "loss": 0.3406,
      "step": 100
    },
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 3.9233157634735107,
      "learning_rate": 4.9210317460317465e-05,
      "loss": 0.2581,
      "step": 200
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 2.671921491622925,
      "learning_rate": 4.8813492063492066e-05,
      "loss": 0.2632,
      "step": 300
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 2.1409311294555664,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 0.262,
      "step": 400
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 1.2217696905136108,
      "learning_rate": 4.801984126984127e-05,
      "loss": 0.2389,
      "step": 500
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 2.9690749645233154,
      "learning_rate": 4.7623015873015875e-05,
      "loss": 0.2202,
      "step": 600
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 2.677267551422119,
      "learning_rate": 4.722619047619048e-05,
      "loss": 0.2507,
      "step": 700
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 3.537749767303467,
      "learning_rate": 4.682936507936508e-05,
      "loss": 0.2368,
      "step": 800
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.8690294623374939,
      "learning_rate": 4.6432539682539684e-05,
      "loss": 0.2451,
      "step": 900
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 1.868816614151001,
      "learning_rate": 4.6035714285714285e-05,
      "loss": 0.2418,
      "step": 1000
    },
    {
      "epoch": 0.873015873015873,
      "grad_norm": 2.9987332820892334,
      "learning_rate": 4.563888888888889e-05,
      "loss": 0.2304,
      "step": 1100
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 3.3610479831695557,
      "learning_rate": 4.52420634920635e-05,
      "loss": 0.2204,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.9470649895178197,
      "eval_loss": 0.21818934381008148,
      "eval_runtime": 8.4481,
      "eval_samples_per_second": 265.149,
      "eval_steps_per_second": 16.572,
      "step": 1260
    },
    {
      "epoch": 1.0317460317460316,
      "grad_norm": 6.474095344543457,
      "learning_rate": 4.4845238095238094e-05,
      "loss": 0.2272,
      "step": 1300
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.6159158945083618,
      "learning_rate": 4.44484126984127e-05,
      "loss": 0.2167,
      "step": 1400
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 2.3044543266296387,
      "learning_rate": 4.40515873015873e-05,
      "loss": 0.2269,
      "step": 1500
    },
    {
      "epoch": 1.2698412698412698,
      "grad_norm": 1.8173353672027588,
      "learning_rate": 4.365476190476191e-05,
      "loss": 0.2048,
      "step": 1600
    },
    {
      "epoch": 1.3492063492063493,
      "grad_norm": 0.686518132686615,
      "learning_rate": 4.325793650793651e-05,
      "loss": 0.2058,
      "step": 1700
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.3616538643836975,
      "learning_rate": 4.286111111111111e-05,
      "loss": 0.2022,
      "step": 1800
    },
    {
      "epoch": 1.507936507936508,
      "grad_norm": 1.3095489740371704,
      "learning_rate": 4.246428571428572e-05,
      "loss": 0.2128,
      "step": 1900
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 0.45151397585868835,
      "learning_rate": 4.206746031746032e-05,
      "loss": 0.1794,
      "step": 2000
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 3.394529104232788,
      "learning_rate": 4.167857142857143e-05,
      "loss": 0.1738,
      "step": 2100
    },
    {
      "epoch": 1.746031746031746,
      "grad_norm": 0.6918357014656067,
      "learning_rate": 4.128174603174603e-05,
      "loss": 0.2037,
      "step": 2200
    },
    {
      "epoch": 1.8253968253968254,
      "grad_norm": 2.3667571544647217,
      "learning_rate": 4.088492063492064e-05,
      "loss": 0.2059,
      "step": 2300
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.9406193494796753,
      "learning_rate": 4.0488095238095245e-05,
      "loss": 0.168,
      "step": 2400
    },
    {
      "epoch": 1.9841269841269842,
      "grad_norm": 1.4899015426635742,
      "learning_rate": 4.009126984126984e-05,
      "loss": 0.2073,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.9606540623403168,
      "eval_loss": 0.20085710287094116,
      "eval_runtime": 8.4031,
      "eval_samples_per_second": 266.57,
      "eval_steps_per_second": 16.661,
      "step": 2520
    },
    {
      "epoch": 2.0634920634920633,
      "grad_norm": 7.05921745300293,
      "learning_rate": 3.9694444444444446e-05,
      "loss": 0.1353,
      "step": 2600
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 1.5735502243041992,
      "learning_rate": 3.929761904761905e-05,
      "loss": 0.1572,
      "step": 2700
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 5.513951778411865,
      "learning_rate": 3.8900793650793655e-05,
      "loss": 0.1543,
      "step": 2800
    },
    {
      "epoch": 2.3015873015873014,
      "grad_norm": 4.703629970550537,
      "learning_rate": 3.8503968253968255e-05,
      "loss": 0.1768,
      "step": 2900
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 4.252865791320801,
      "learning_rate": 3.8107142857142856e-05,
      "loss": 0.171,
      "step": 3000
    },
    {
      "epoch": 2.4603174603174605,
      "grad_norm": 2.51863431930542,
      "learning_rate": 3.7710317460317464e-05,
      "loss": 0.1542,
      "step": 3100
    },
    {
      "epoch": 2.5396825396825395,
      "grad_norm": 1.9726319313049316,
      "learning_rate": 3.7313492063492064e-05,
      "loss": 0.1853,
      "step": 3200
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 2.2101259231567383,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 0.1697,
      "step": 3300
    },
    {
      "epoch": 2.6984126984126986,
      "grad_norm": 1.7396907806396484,
      "learning_rate": 3.651984126984127e-05,
      "loss": 0.1736,
      "step": 3400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 6.003996849060059,
      "learning_rate": 3.612301587301587e-05,
      "loss": 0.1865,
      "step": 3500
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 3.976580858230591,
      "learning_rate": 3.572619047619048e-05,
      "loss": 0.1678,
      "step": 3600
    },
    {
      "epoch": 2.9365079365079367,
      "grad_norm": 3.349900484085083,
      "learning_rate": 3.532936507936508e-05,
      "loss": 0.1503,
      "step": 3700
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.9608194622279129,
      "eval_loss": 0.18753916025161743,
      "eval_runtime": 8.4183,
      "eval_samples_per_second": 266.087,
      "eval_steps_per_second": 16.63,
      "step": 3780
    },
    {
      "epoch": 3.015873015873016,
      "grad_norm": 2.5197150707244873,
      "learning_rate": 3.493253968253968e-05,
      "loss": 0.1546,
      "step": 3800
    },
    {
      "epoch": 3.0952380952380953,
      "grad_norm": 3.1020188331604004,
      "learning_rate": 3.453571428571429e-05,
      "loss": 0.1479,
      "step": 3900
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 3.5583746433258057,
      "learning_rate": 3.413888888888889e-05,
      "loss": 0.1373,
      "step": 4000
    },
    {
      "epoch": 3.253968253968254,
      "grad_norm": 8.258296012878418,
      "learning_rate": 3.3746031746031746e-05,
      "loss": 0.1492,
      "step": 4100
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.8839887976646423,
      "learning_rate": 3.334920634920635e-05,
      "loss": 0.1629,
      "step": 4200
    },
    {
      "epoch": 3.4126984126984126,
      "grad_norm": 3.3709263801574707,
      "learning_rate": 3.2952380952380954e-05,
      "loss": 0.159,
      "step": 4300
    },
    {
      "epoch": 3.492063492063492,
      "grad_norm": 1.6590549945831299,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 0.1263,
      "step": 4400
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.6658000946044922,
      "learning_rate": 3.215873015873016e-05,
      "loss": 0.1407,
      "step": 4500
    },
    {
      "epoch": 3.6507936507936507,
      "grad_norm": 4.383174896240234,
      "learning_rate": 3.176190476190476e-05,
      "loss": 0.1358,
      "step": 4600
    },
    {
      "epoch": 3.7301587301587302,
      "grad_norm": 3.5856854915618896,
      "learning_rate": 3.1365079365079364e-05,
      "loss": 0.155,
      "step": 4700
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 2.219209671020508,
      "learning_rate": 3.096825396825397e-05,
      "loss": 0.1373,
      "step": 4800
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 1.645674228668213,
      "learning_rate": 3.057142857142857e-05,
      "loss": 0.152,
      "step": 4900
    },
    {
      "epoch": 3.9682539682539684,
      "grad_norm": 2.9899933338165283,
      "learning_rate": 3.0174603174603176e-05,
      "loss": 0.1212,
      "step": 5000
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.9637014314928426,
      "eval_loss": 0.2154528796672821,
      "eval_runtime": 8.3915,
      "eval_samples_per_second": 266.938,
      "eval_steps_per_second": 16.684,
      "step": 5040
    },
    {
      "epoch": 4.0476190476190474,
      "grad_norm": 3.388838529586792,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.1386,
      "step": 5100
    },
    {
      "epoch": 4.1269841269841265,
      "grad_norm": 5.62322473526001,
      "learning_rate": 2.938095238095238e-05,
      "loss": 0.1317,
      "step": 5200
    },
    {
      "epoch": 4.2063492063492065,
      "grad_norm": 0.4899159073829651,
      "learning_rate": 2.8984126984126985e-05,
      "loss": 0.1184,
      "step": 5300
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 2.9610471725463867,
      "learning_rate": 2.858730158730159e-05,
      "loss": 0.129,
      "step": 5400
    },
    {
      "epoch": 4.365079365079365,
      "grad_norm": 4.1480512619018555,
      "learning_rate": 2.819047619047619e-05,
      "loss": 0.1165,
      "step": 5500
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.28372862935066223,
      "learning_rate": 2.7793650793650794e-05,
      "loss": 0.1203,
      "step": 5600
    },
    {
      "epoch": 4.523809523809524,
      "grad_norm": 1.3323627710342407,
      "learning_rate": 2.7396825396825398e-05,
      "loss": 0.1148,
      "step": 5700
    },
    {
      "epoch": 4.603174603174603,
      "grad_norm": 1.0863605737686157,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.1106,
      "step": 5800
    },
    {
      "epoch": 4.682539682539683,
      "grad_norm": 2.113987445831299,
      "learning_rate": 2.6603174603174603e-05,
      "loss": 0.1321,
      "step": 5900
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.5355978012084961,
      "learning_rate": 2.6206349206349207e-05,
      "loss": 0.1206,
      "step": 6000
    },
    {
      "epoch": 4.841269841269841,
      "grad_norm": 5.440301418304443,
      "learning_rate": 2.580952380952381e-05,
      "loss": 0.1165,
      "step": 6100
    },
    {
      "epoch": 4.920634920634921,
      "grad_norm": 3.2319297790527344,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 0.0962,
      "step": 6200
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.42565932869911194,
      "learning_rate": 2.501984126984127e-05,
      "loss": 0.122,
      "step": 6300
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.9594383775351013,
      "eval_loss": 0.21710045635700226,
      "eval_runtime": 8.4498,
      "eval_samples_per_second": 265.094,
      "eval_steps_per_second": 16.568,
      "step": 6300
    },
    {
      "epoch": 5.079365079365079,
      "grad_norm": 11.30163860321045,
      "learning_rate": 2.4623015873015875e-05,
      "loss": 0.0793,
      "step": 6400
    },
    {
      "epoch": 5.158730158730159,
      "grad_norm": 3.1020188331604004,
      "learning_rate": 2.4226190476190476e-05,
      "loss": 0.1028,
      "step": 6500
    },
    {
      "epoch": 5.238095238095238,
      "grad_norm": 5.807809829711914,
      "learning_rate": 2.3829365079365083e-05,
      "loss": 0.1018,
      "step": 6600
    },
    {
      "epoch": 5.317460317460317,
      "grad_norm": 2.6364710330963135,
      "learning_rate": 2.3432539682539684e-05,
      "loss": 0.0954,
      "step": 6700
    },
    {
      "epoch": 5.396825396825397,
      "grad_norm": 5.214683532714844,
      "learning_rate": 2.3035714285714285e-05,
      "loss": 0.0873,
      "step": 6800
    },
    {
      "epoch": 5.476190476190476,
      "grad_norm": 3.8969907760620117,
      "learning_rate": 2.263888888888889e-05,
      "loss": 0.0873,
      "step": 6900
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.04352148622274399,
      "learning_rate": 2.2242063492063493e-05,
      "loss": 0.0955,
      "step": 7000
    },
    {
      "epoch": 5.634920634920634,
      "grad_norm": 4.368758201599121,
      "learning_rate": 2.1845238095238097e-05,
      "loss": 0.1081,
      "step": 7100
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.15477582812309265,
      "learning_rate": 2.1452380952380956e-05,
      "loss": 0.0869,
      "step": 7200
    },
    {
      "epoch": 5.7936507936507935,
      "grad_norm": 1.0296449661254883,
      "learning_rate": 2.1055555555555556e-05,
      "loss": 0.0994,
      "step": 7300
    },
    {
      "epoch": 5.8730158730158735,
      "grad_norm": 8.25109577178955,
      "learning_rate": 2.065873015873016e-05,
      "loss": 0.1022,
      "step": 7400
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 4.180516242980957,
      "learning_rate": 2.026190476190476e-05,
      "loss": 0.0936,
      "step": 7500
    },
    {
      "epoch": 6.0,
      "eval_f1": 0.9633960345704117,
      "eval_loss": 0.28119957447052,
      "eval_runtime": 8.3521,
      "eval_samples_per_second": 268.196,
      "eval_steps_per_second": 16.762,
      "step": 7560
    },
    {
      "epoch": 6.031746031746032,
      "grad_norm": 0.7584093809127808,
      "learning_rate": 1.9865079365079365e-05,
      "loss": 0.1043,
      "step": 7600
    },
    {
      "epoch": 6.111111111111111,
      "grad_norm": 2.9542462825775146,
      "learning_rate": 1.946825396825397e-05,
      "loss": 0.0685,
      "step": 7700
    },
    {
      "epoch": 6.190476190476191,
      "grad_norm": 0.11259892582893372,
      "learning_rate": 1.9071428571428574e-05,
      "loss": 0.0742,
      "step": 7800
    },
    {
      "epoch": 6.26984126984127,
      "grad_norm": 0.1515951156616211,
      "learning_rate": 1.8674603174603174e-05,
      "loss": 0.0708,
      "step": 7900
    },
    {
      "epoch": 6.349206349206349,
      "grad_norm": 4.816314697265625,
      "learning_rate": 1.827777777777778e-05,
      "loss": 0.0782,
      "step": 8000
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 21.45929527282715,
      "learning_rate": 1.7880952380952383e-05,
      "loss": 0.0853,
      "step": 8100
    },
    {
      "epoch": 6.507936507936508,
      "grad_norm": 5.849556922912598,
      "learning_rate": 1.7484126984126987e-05,
      "loss": 0.0823,
      "step": 8200
    },
    {
      "epoch": 6.587301587301587,
      "grad_norm": 4.141535758972168,
      "learning_rate": 1.7087301587301588e-05,
      "loss": 0.0712,
      "step": 8300
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 3.9628095626831055,
      "learning_rate": 1.669047619047619e-05,
      "loss": 0.0688,
      "step": 8400
    },
    {
      "epoch": 6.746031746031746,
      "grad_norm": 0.6566713452339172,
      "learning_rate": 1.6293650793650796e-05,
      "loss": 0.0983,
      "step": 8500
    },
    {
      "epoch": 6.825396825396825,
      "grad_norm": 6.575402736663818,
      "learning_rate": 1.58968253968254e-05,
      "loss": 0.0885,
      "step": 8600
    },
    {
      "epoch": 6.904761904761905,
      "grad_norm": 0.7486171126365662,
      "learning_rate": 1.55e-05,
      "loss": 0.0952,
      "step": 8700
    },
    {
      "epoch": 6.984126984126984,
      "grad_norm": 0.2635714113712311,
      "learning_rate": 1.5103174603174605e-05,
      "loss": 0.1075,
      "step": 8800
    },
    {
      "epoch": 7.0,
      "eval_f1": 0.965711361310133,
      "eval_loss": 0.28382349014282227,
      "eval_runtime": 8.4237,
      "eval_samples_per_second": 265.916,
      "eval_steps_per_second": 16.62,
      "step": 8820
    },
    {
      "epoch": 7.063492063492063,
      "grad_norm": 4.609632968902588,
      "learning_rate": 1.4706349206349207e-05,
      "loss": 0.055,
      "step": 8900
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.085135817527771,
      "learning_rate": 1.4309523809523811e-05,
      "loss": 0.0622,
      "step": 9000
    },
    {
      "epoch": 7.222222222222222,
      "grad_norm": 0.06196296215057373,
      "learning_rate": 1.3912698412698414e-05,
      "loss": 0.0748,
      "step": 9100
    },
    {
      "epoch": 7.301587301587301,
      "grad_norm": 5.303059101104736,
      "learning_rate": 1.3515873015873018e-05,
      "loss": 0.0511,
      "step": 9200
    },
    {
      "epoch": 7.380952380952381,
      "grad_norm": 0.35476773977279663,
      "learning_rate": 1.311904761904762e-05,
      "loss": 0.0641,
      "step": 9300
    },
    {
      "epoch": 7.4603174603174605,
      "grad_norm": 0.2052101045846939,
      "learning_rate": 1.2722222222222221e-05,
      "loss": 0.0917,
      "step": 9400
    },
    {
      "epoch": 7.5396825396825395,
      "grad_norm": 5.1729254722595215,
      "learning_rate": 1.2325396825396827e-05,
      "loss": 0.0825,
      "step": 9500
    },
    {
      "epoch": 7.619047619047619,
      "grad_norm": 0.07350274175405502,
      "learning_rate": 1.192857142857143e-05,
      "loss": 0.0687,
      "step": 9600
    },
    {
      "epoch": 7.698412698412699,
      "grad_norm": 0.07587892562150955,
      "learning_rate": 1.1535714285714286e-05,
      "loss": 0.0678,
      "step": 9700
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 11.585566520690918,
      "learning_rate": 1.1138888888888889e-05,
      "loss": 0.0796,
      "step": 9800
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 6.688920021057129,
      "learning_rate": 1.0742063492063493e-05,
      "loss": 0.049,
      "step": 9900
    },
    {
      "epoch": 7.936507936507937,
      "grad_norm": 0.0025360577274113894,
      "learning_rate": 1.0345238095238095e-05,
      "loss": 0.068,
      "step": 10000
    },
    {
      "epoch": 8.0,
      "eval_f1": 0.9660319094184251,
      "eval_loss": 0.3061898350715637,
      "eval_runtime": 8.4252,
      "eval_samples_per_second": 265.868,
      "eval_steps_per_second": 16.617,
      "step": 10080
    },
    {
      "epoch": 8.015873015873016,
      "grad_norm": 0.09899129718542099,
      "learning_rate": 9.948412698412698e-06,
      "loss": 0.0688,
      "step": 10100
    },
    {
      "epoch": 8.095238095238095,
      "grad_norm": 0.38804760575294495,
      "learning_rate": 9.551587301587302e-06,
      "loss": 0.0504,
      "step": 10200
    },
    {
      "epoch": 8.174603174603174,
      "grad_norm": 0.2074349820613861,
      "learning_rate": 9.154761904761904e-06,
      "loss": 0.0455,
      "step": 10300
    },
    {
      "epoch": 8.253968253968253,
      "grad_norm": 0.1893724650144577,
      "learning_rate": 8.757936507936508e-06,
      "loss": 0.0619,
      "step": 10400
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.005965872667729855,
      "learning_rate": 8.361111111111111e-06,
      "loss": 0.0648,
      "step": 10500
    },
    {
      "epoch": 8.412698412698413,
      "grad_norm": 12.638755798339844,
      "learning_rate": 7.964285714285715e-06,
      "loss": 0.064,
      "step": 10600
    },
    {
      "epoch": 8.492063492063492,
      "grad_norm": 0.008731933310627937,
      "learning_rate": 7.567460317460317e-06,
      "loss": 0.0692,
      "step": 10700
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.023555748164653778,
      "learning_rate": 7.170634920634921e-06,
      "loss": 0.0469,
      "step": 10800
    },
    {
      "epoch": 8.65079365079365,
      "grad_norm": 0.02029404044151306,
      "learning_rate": 6.773809523809524e-06,
      "loss": 0.0346,
      "step": 10900
    },
    {
      "epoch": 8.73015873015873,
      "grad_norm": 0.05799514800310135,
      "learning_rate": 6.376984126984127e-06,
      "loss": 0.0466,
      "step": 11000
    },
    {
      "epoch": 8.80952380952381,
      "grad_norm": 0.00677134795114398,
      "learning_rate": 5.9801587301587305e-06,
      "loss": 0.0686,
      "step": 11100
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 7.3584489822387695,
      "learning_rate": 5.583333333333334e-06,
      "loss": 0.0596,
      "step": 11200
    },
    {
      "epoch": 8.968253968253968,
      "grad_norm": 1.8106539249420166,
      "learning_rate": 5.186507936507936e-06,
      "loss": 0.0488,
      "step": 11300
    },
    {
      "epoch": 9.0,
      "eval_f1": 0.9641844885338829,
      "eval_loss": 0.33790186047554016,
      "eval_runtime": 8.4246,
      "eval_samples_per_second": 265.888,
      "eval_steps_per_second": 16.618,
      "step": 11340
    },
    {
      "epoch": 9.047619047619047,
      "grad_norm": 0.007686763070523739,
      "learning_rate": 4.7896825396825395e-06,
      "loss": 0.0503,
      "step": 11400
    },
    {
      "epoch": 9.126984126984127,
      "grad_norm": 20.121734619140625,
      "learning_rate": 4.392857142857143e-06,
      "loss": 0.063,
      "step": 11500
    },
    {
      "epoch": 9.206349206349206,
      "grad_norm": 3.1249442100524902,
      "learning_rate": 3.996031746031746e-06,
      "loss": 0.0517,
      "step": 11600
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.012443668209016323,
      "learning_rate": 3.5992063492063493e-06,
      "loss": 0.047,
      "step": 11700
    },
    {
      "epoch": 9.365079365079366,
      "grad_norm": 0.5765857696533203,
      "learning_rate": 3.2023809523809526e-06,
      "loss": 0.046,
      "step": 11800
    },
    {
      "epoch": 9.444444444444445,
      "grad_norm": 0.03435327112674713,
      "learning_rate": 2.8095238095238096e-06,
      "loss": 0.0642,
      "step": 11900
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.0907578319311142,
      "learning_rate": 2.412698412698413e-06,
      "loss": 0.0471,
      "step": 12000
    },
    {
      "epoch": 9.603174603174603,
      "grad_norm": 0.029899945482611656,
      "learning_rate": 2.0158730158730158e-06,
      "loss": 0.0477,
      "step": 12100
    },
    {
      "epoch": 9.682539682539682,
      "grad_norm": 14.351895332336426,
      "learning_rate": 1.619047619047619e-06,
      "loss": 0.0518,
      "step": 12200
    },
    {
      "epoch": 9.761904761904763,
      "grad_norm": 0.004439854063093662,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.0454,
      "step": 12300
    },
    {
      "epoch": 9.841269841269842,
      "grad_norm": 4.101274013519287,
      "learning_rate": 8.253968253968255e-07,
      "loss": 0.0349,
      "step": 12400
    },
    {
      "epoch": 9.920634920634921,
      "grad_norm": 0.7238494753837585,
      "learning_rate": 4.285714285714286e-07,
      "loss": 0.0545,
      "step": 12500
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.2963845431804657,
      "learning_rate": 3.1746031746031744e-08,
      "loss": 0.0401,
      "step": 12600
    },
    {
      "epoch": 10.0,
      "eval_f1": 0.9661016949152542,
      "eval_loss": 0.3438822627067566,
      "eval_runtime": 8.4471,
      "eval_samples_per_second": 265.181,
      "eval_steps_per_second": 16.574,
      "step": 12600
    }
  ],
  "logging_steps": 100,
  "max_steps": 12600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.32568505243136e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
