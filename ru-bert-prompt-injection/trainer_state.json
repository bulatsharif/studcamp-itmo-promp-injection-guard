{
  "best_global_step": 5199,
  "best_metric": 0.17585870623588562,
  "best_model_checkpoint": "/kaggle/working/results/checkpoint-5199",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 17330,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05770340450086555,
      "grad_norm": 1.9134494066238403,
      "learning_rate": 4.971436814772072e-05,
      "loss": 0.401,
      "step": 100
    },
    {
      "epoch": 0.1154068090017311,
      "grad_norm": 2.37727689743042,
      "learning_rate": 4.942585112521639e-05,
      "loss": 0.29,
      "step": 200
    },
    {
      "epoch": 0.17311021350259664,
      "grad_norm": 3.438066244125366,
      "learning_rate": 4.913733410271206e-05,
      "loss": 0.2771,
      "step": 300
    },
    {
      "epoch": 0.2308136180034622,
      "grad_norm": 1.8033599853515625,
      "learning_rate": 4.884881708020774e-05,
      "loss": 0.2565,
      "step": 400
    },
    {
      "epoch": 0.28851702250432776,
      "grad_norm": 1.6544028520584106,
      "learning_rate": 4.8560300057703405e-05,
      "loss": 0.2522,
      "step": 500
    },
    {
      "epoch": 0.3462204270051933,
      "grad_norm": 2.0028433799743652,
      "learning_rate": 4.827178303519908e-05,
      "loss": 0.2203,
      "step": 600
    },
    {
      "epoch": 0.4039238315060589,
      "grad_norm": 3.558250904083252,
      "learning_rate": 4.798326601269475e-05,
      "loss": 0.2468,
      "step": 700
    },
    {
      "epoch": 0.4616272360069244,
      "grad_norm": 4.321540832519531,
      "learning_rate": 4.7697634160415465e-05,
      "loss": 0.2696,
      "step": 800
    },
    {
      "epoch": 0.51933064050779,
      "grad_norm": 5.930453300476074,
      "learning_rate": 4.740911713791114e-05,
      "loss": 0.223,
      "step": 900
    },
    {
      "epoch": 0.5770340450086555,
      "grad_norm": 1.313973307609558,
      "learning_rate": 4.712060011540681e-05,
      "loss": 0.2449,
      "step": 1000
    },
    {
      "epoch": 0.634737449509521,
      "grad_norm": 2.1723079681396484,
      "learning_rate": 4.683208309290249e-05,
      "loss": 0.2472,
      "step": 1100
    },
    {
      "epoch": 0.6924408540103866,
      "grad_norm": 3.5288808345794678,
      "learning_rate": 4.6543566070398155e-05,
      "loss": 0.2317,
      "step": 1200
    },
    {
      "epoch": 0.7501442585112522,
      "grad_norm": 0.37580764293670654,
      "learning_rate": 4.625504904789383e-05,
      "loss": 0.2238,
      "step": 1300
    },
    {
      "epoch": 0.8078476630121177,
      "grad_norm": 2.1535439491271973,
      "learning_rate": 4.59665320253895e-05,
      "loss": 0.2295,
      "step": 1400
    },
    {
      "epoch": 0.8655510675129833,
      "grad_norm": 3.533620834350586,
      "learning_rate": 4.567801500288517e-05,
      "loss": 0.2379,
      "step": 1500
    },
    {
      "epoch": 0.9232544720138488,
      "grad_norm": 2.641916275024414,
      "learning_rate": 4.5389497980380844e-05,
      "loss": 0.2141,
      "step": 1600
    },
    {
      "epoch": 0.9809578765147143,
      "grad_norm": 4.024497032165527,
      "learning_rate": 4.510098095787652e-05,
      "loss": 0.2279,
      "step": 1700
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.927608587119321,
      "eval_loss": 0.26908984780311584,
      "eval_runtime": 11.3763,
      "eval_samples_per_second": 270.826,
      "eval_steps_per_second": 16.965,
      "step": 1733
    },
    {
      "epoch": 1.03866128101558,
      "grad_norm": 1.7119449377059937,
      "learning_rate": 4.481246393537219e-05,
      "loss": 0.1909,
      "step": 1800
    },
    {
      "epoch": 1.0963646855164455,
      "grad_norm": 2.335664749145508,
      "learning_rate": 4.452394691286786e-05,
      "loss": 0.2082,
      "step": 1900
    },
    {
      "epoch": 1.154068090017311,
      "grad_norm": 1.6011825799942017,
      "learning_rate": 4.4235429890363534e-05,
      "loss": 0.1964,
      "step": 2000
    },
    {
      "epoch": 1.2117714945181766,
      "grad_norm": 5.692823886871338,
      "learning_rate": 4.394691286785921e-05,
      "loss": 0.1932,
      "step": 2100
    },
    {
      "epoch": 1.269474899019042,
      "grad_norm": 5.604025363922119,
      "learning_rate": 4.3658395845354875e-05,
      "loss": 0.2029,
      "step": 2200
    },
    {
      "epoch": 1.3271783035199076,
      "grad_norm": 1.3553825616836548,
      "learning_rate": 4.336987882285055e-05,
      "loss": 0.1832,
      "step": 2300
    },
    {
      "epoch": 1.3848817080207732,
      "grad_norm": 4.758021354675293,
      "learning_rate": 4.308136180034622e-05,
      "loss": 0.1689,
      "step": 2400
    },
    {
      "epoch": 1.442585112521639,
      "grad_norm": 3.9654831886291504,
      "learning_rate": 4.27928447778419e-05,
      "loss": 0.21,
      "step": 2500
    },
    {
      "epoch": 1.5002885170225042,
      "grad_norm": 2.200322151184082,
      "learning_rate": 4.250432775533757e-05,
      "loss": 0.1748,
      "step": 2600
    },
    {
      "epoch": 1.55799192152337,
      "grad_norm": 4.037695407867432,
      "learning_rate": 4.221581073283324e-05,
      "loss": 0.159,
      "step": 2700
    },
    {
      "epoch": 1.6156953260242353,
      "grad_norm": 4.031235218048096,
      "learning_rate": 4.192729371032891e-05,
      "loss": 0.1782,
      "step": 2800
    },
    {
      "epoch": 1.673398730525101,
      "grad_norm": 2.92433500289917,
      "learning_rate": 4.1641661858049625e-05,
      "loss": 0.1985,
      "step": 2900
    },
    {
      "epoch": 1.7311021350259665,
      "grad_norm": 3.3963582515716553,
      "learning_rate": 4.13531448355453e-05,
      "loss": 0.2094,
      "step": 3000
    },
    {
      "epoch": 1.788805539526832,
      "grad_norm": 2.895864486694336,
      "learning_rate": 4.106462781304097e-05,
      "loss": 0.1955,
      "step": 3100
    },
    {
      "epoch": 1.8465089440276976,
      "grad_norm": 8.078753471374512,
      "learning_rate": 4.077611079053664e-05,
      "loss": 0.1921,
      "step": 3200
    },
    {
      "epoch": 1.9042123485285631,
      "grad_norm": 0.6481674909591675,
      "learning_rate": 4.0487593768032315e-05,
      "loss": 0.1799,
      "step": 3300
    },
    {
      "epoch": 1.9619157530294289,
      "grad_norm": 0.47889065742492676,
      "learning_rate": 4.019907674552799e-05,
      "loss": 0.1696,
      "step": 3400
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.9423076923076923,
      "eval_loss": 0.22198361158370972,
      "eval_runtime": 11.3322,
      "eval_samples_per_second": 271.879,
      "eval_steps_per_second": 17.031,
      "step": 3466
    },
    {
      "epoch": 2.019619157530294,
      "grad_norm": 8.460320472717285,
      "learning_rate": 3.991055972302366e-05,
      "loss": 0.1625,
      "step": 3500
    },
    {
      "epoch": 2.07732256203116,
      "grad_norm": 4.062798500061035,
      "learning_rate": 3.962204270051934e-05,
      "loss": 0.1709,
      "step": 3600
    },
    {
      "epoch": 2.1350259665320253,
      "grad_norm": 0.30770131945610046,
      "learning_rate": 3.9333525678015004e-05,
      "loss": 0.1407,
      "step": 3700
    },
    {
      "epoch": 2.192729371032891,
      "grad_norm": 0.5569746494293213,
      "learning_rate": 3.904500865551068e-05,
      "loss": 0.1659,
      "step": 3800
    },
    {
      "epoch": 2.2504327755337563,
      "grad_norm": 3.0017611980438232,
      "learning_rate": 3.8756491633006345e-05,
      "loss": 0.1572,
      "step": 3900
    },
    {
      "epoch": 2.308136180034622,
      "grad_norm": 2.2083842754364014,
      "learning_rate": 3.846797461050202e-05,
      "loss": 0.1669,
      "step": 4000
    },
    {
      "epoch": 2.365839584535488,
      "grad_norm": 3.854295015335083,
      "learning_rate": 3.8179457587997694e-05,
      "loss": 0.1691,
      "step": 4100
    },
    {
      "epoch": 2.423542989036353,
      "grad_norm": 0.2854851186275482,
      "learning_rate": 3.789094056549337e-05,
      "loss": 0.1593,
      "step": 4200
    },
    {
      "epoch": 2.481246393537219,
      "grad_norm": 7.161818027496338,
      "learning_rate": 3.760242354298904e-05,
      "loss": 0.1464,
      "step": 4300
    },
    {
      "epoch": 2.538949798038084,
      "grad_norm": 1.6100542545318604,
      "learning_rate": 3.731390652048471e-05,
      "loss": 0.1614,
      "step": 4400
    },
    {
      "epoch": 2.59665320253895,
      "grad_norm": 2.1859378814697266,
      "learning_rate": 3.702538949798038e-05,
      "loss": 0.1701,
      "step": 4500
    },
    {
      "epoch": 2.6543566070398152,
      "grad_norm": 1.9533330202102661,
      "learning_rate": 3.673687247547605e-05,
      "loss": 0.1674,
      "step": 4600
    },
    {
      "epoch": 2.712060011540681,
      "grad_norm": 6.264248371124268,
      "learning_rate": 3.6448355452971724e-05,
      "loss": 0.1651,
      "step": 4700
    },
    {
      "epoch": 2.7697634160415463,
      "grad_norm": 6.934405326843262,
      "learning_rate": 3.6159838430467405e-05,
      "loss": 0.1519,
      "step": 4800
    },
    {
      "epoch": 2.827466820542412,
      "grad_norm": 0.7867162823677063,
      "learning_rate": 3.587132140796307e-05,
      "loss": 0.1651,
      "step": 4900
    },
    {
      "epoch": 2.885170225043278,
      "grad_norm": 0.4724369943141937,
      "learning_rate": 3.5585689555683785e-05,
      "loss": 0.1342,
      "step": 5000
    },
    {
      "epoch": 2.942873629544143,
      "grad_norm": 5.8497161865234375,
      "learning_rate": 3.529717253317946e-05,
      "loss": 0.1642,
      "step": 5100
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.9504238376573337,
      "eval_loss": 0.17585870623588562,
      "eval_runtime": 11.3434,
      "eval_samples_per_second": 271.61,
      "eval_steps_per_second": 17.014,
      "step": 5199
    },
    {
      "epoch": 3.000577034045009,
      "grad_norm": 2.533379316329956,
      "learning_rate": 3.500865551067513e-05,
      "loss": 0.1554,
      "step": 5200
    },
    {
      "epoch": 3.058280438545874,
      "grad_norm": 0.16912776231765747,
      "learning_rate": 3.472013848817081e-05,
      "loss": 0.1351,
      "step": 5300
    },
    {
      "epoch": 3.11598384304674,
      "grad_norm": 2.0414328575134277,
      "learning_rate": 3.4431621465666475e-05,
      "loss": 0.117,
      "step": 5400
    },
    {
      "epoch": 3.1736872475476052,
      "grad_norm": 2.251631736755371,
      "learning_rate": 3.414310444316215e-05,
      "loss": 0.1411,
      "step": 5500
    },
    {
      "epoch": 3.231390652048471,
      "grad_norm": 1.8398860692977905,
      "learning_rate": 3.3854587420657816e-05,
      "loss": 0.1346,
      "step": 5600
    },
    {
      "epoch": 3.2890940565493363,
      "grad_norm": 3.9283275604248047,
      "learning_rate": 3.356607039815349e-05,
      "loss": 0.1265,
      "step": 5700
    },
    {
      "epoch": 3.346797461050202,
      "grad_norm": 4.919632911682129,
      "learning_rate": 3.327755337564917e-05,
      "loss": 0.1202,
      "step": 5800
    },
    {
      "epoch": 3.4045008655510673,
      "grad_norm": 7.881026744842529,
      "learning_rate": 3.298903635314484e-05,
      "loss": 0.1321,
      "step": 5900
    },
    {
      "epoch": 3.462204270051933,
      "grad_norm": 3.4006853103637695,
      "learning_rate": 3.270051933064051e-05,
      "loss": 0.1199,
      "step": 6000
    },
    {
      "epoch": 3.5199076745527984,
      "grad_norm": 5.773479461669922,
      "learning_rate": 3.241200230813618e-05,
      "loss": 0.141,
      "step": 6100
    },
    {
      "epoch": 3.577611079053664,
      "grad_norm": 0.17079776525497437,
      "learning_rate": 3.2123485285631853e-05,
      "loss": 0.1379,
      "step": 6200
    },
    {
      "epoch": 3.63531448355453,
      "grad_norm": 0.7728154063224792,
      "learning_rate": 3.183496826312752e-05,
      "loss": 0.1477,
      "step": 6300
    },
    {
      "epoch": 3.693017888055395,
      "grad_norm": 6.5027971267700195,
      "learning_rate": 3.15464512406232e-05,
      "loss": 0.1418,
      "step": 6400
    },
    {
      "epoch": 3.750721292556261,
      "grad_norm": 0.21568350493907928,
      "learning_rate": 3.1257934218118876e-05,
      "loss": 0.1207,
      "step": 6500
    },
    {
      "epoch": 3.8084246970571263,
      "grad_norm": 5.339821815490723,
      "learning_rate": 3.096941719561454e-05,
      "loss": 0.1368,
      "step": 6600
    },
    {
      "epoch": 3.866128101557992,
      "grad_norm": 0.47310757637023926,
      "learning_rate": 3.068090017311022e-05,
      "loss": 0.1497,
      "step": 6700
    },
    {
      "epoch": 3.9238315060588573,
      "grad_norm": 0.7620674967765808,
      "learning_rate": 3.0392383150605884e-05,
      "loss": 0.1267,
      "step": 6800
    },
    {
      "epoch": 3.981534910559723,
      "grad_norm": 4.822976589202881,
      "learning_rate": 3.0103866128101558e-05,
      "loss": 0.1369,
      "step": 6900
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.9531329597554763,
      "eval_loss": 0.20798633992671967,
      "eval_runtime": 11.3937,
      "eval_samples_per_second": 270.412,
      "eval_steps_per_second": 16.939,
      "step": 6932
    },
    {
      "epoch": 4.039238315060588,
      "grad_norm": 2.5322718620300293,
      "learning_rate": 2.9818234275822278e-05,
      "loss": 0.1023,
      "step": 7000
    },
    {
      "epoch": 4.096941719561454,
      "grad_norm": 0.08492725342512131,
      "learning_rate": 2.9529717253317945e-05,
      "loss": 0.1129,
      "step": 7100
    },
    {
      "epoch": 4.15464512406232,
      "grad_norm": 5.4123687744140625,
      "learning_rate": 2.924120023081362e-05,
      "loss": 0.0904,
      "step": 7200
    },
    {
      "epoch": 4.212348528563186,
      "grad_norm": 6.480058670043945,
      "learning_rate": 2.895268320830929e-05,
      "loss": 0.1154,
      "step": 7300
    },
    {
      "epoch": 4.2700519330640505,
      "grad_norm": 4.925212860107422,
      "learning_rate": 2.8664166185804964e-05,
      "loss": 0.1036,
      "step": 7400
    },
    {
      "epoch": 4.327755337564916,
      "grad_norm": 0.13598956167697906,
      "learning_rate": 2.837853433352568e-05,
      "loss": 0.1186,
      "step": 7500
    },
    {
      "epoch": 4.385458742065782,
      "grad_norm": 2.6106388568878174,
      "learning_rate": 2.809001731102135e-05,
      "loss": 0.1107,
      "step": 7600
    },
    {
      "epoch": 4.443162146566648,
      "grad_norm": 4.049017906188965,
      "learning_rate": 2.7801500288517025e-05,
      "loss": 0.1112,
      "step": 7700
    },
    {
      "epoch": 4.500865551067513,
      "grad_norm": 9.198232650756836,
      "learning_rate": 2.75129832660127e-05,
      "loss": 0.1112,
      "step": 7800
    },
    {
      "epoch": 4.558568955568378,
      "grad_norm": 7.474204063415527,
      "learning_rate": 2.7224466243508366e-05,
      "loss": 0.1396,
      "step": 7900
    },
    {
      "epoch": 4.616272360069244,
      "grad_norm": 2.691718101501465,
      "learning_rate": 2.6935949221004043e-05,
      "loss": 0.1073,
      "step": 8000
    },
    {
      "epoch": 4.67397576457011,
      "grad_norm": 2.0123724937438965,
      "learning_rate": 2.664743219849971e-05,
      "loss": 0.1227,
      "step": 8100
    },
    {
      "epoch": 4.731679169070976,
      "grad_norm": 0.6108522415161133,
      "learning_rate": 2.6358915175995385e-05,
      "loss": 0.1173,
      "step": 8200
    },
    {
      "epoch": 4.7893825735718405,
      "grad_norm": 0.481637179851532,
      "learning_rate": 2.6070398153491055e-05,
      "loss": 0.1045,
      "step": 8300
    },
    {
      "epoch": 4.847085978072706,
      "grad_norm": 1.4510258436203003,
      "learning_rate": 2.578188113098673e-05,
      "loss": 0.1056,
      "step": 8400
    },
    {
      "epoch": 4.904789382573572,
      "grad_norm": 10.236169815063477,
      "learning_rate": 2.5493364108482403e-05,
      "loss": 0.1203,
      "step": 8500
    },
    {
      "epoch": 4.962492787074438,
      "grad_norm": 8.779041290283203,
      "learning_rate": 2.5204847085978074e-05,
      "loss": 0.1268,
      "step": 8600
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.9541188738269031,
      "eval_loss": 0.1942460834980011,
      "eval_runtime": 11.379,
      "eval_samples_per_second": 270.762,
      "eval_steps_per_second": 16.961,
      "step": 8665
    },
    {
      "epoch": 5.020196191575303,
      "grad_norm": 4.545224666595459,
      "learning_rate": 2.4916330063473748e-05,
      "loss": 0.0969,
      "step": 8700
    },
    {
      "epoch": 5.077899596076168,
      "grad_norm": 6.151360511779785,
      "learning_rate": 2.462781304096942e-05,
      "loss": 0.0917,
      "step": 8800
    },
    {
      "epoch": 5.135603000577034,
      "grad_norm": 6.530242919921875,
      "learning_rate": 2.433929601846509e-05,
      "loss": 0.0947,
      "step": 8900
    },
    {
      "epoch": 5.1933064050779,
      "grad_norm": 6.829822540283203,
      "learning_rate": 2.4050778995960764e-05,
      "loss": 0.0793,
      "step": 9000
    },
    {
      "epoch": 5.251009809578765,
      "grad_norm": 2.560105800628662,
      "learning_rate": 2.3762261973456434e-05,
      "loss": 0.0859,
      "step": 9100
    },
    {
      "epoch": 5.3087132140796305,
      "grad_norm": 4.633632659912109,
      "learning_rate": 2.3473744950952105e-05,
      "loss": 0.0772,
      "step": 9200
    },
    {
      "epoch": 5.366416618580496,
      "grad_norm": 0.07577700912952423,
      "learning_rate": 2.3185227928447782e-05,
      "loss": 0.079,
      "step": 9300
    },
    {
      "epoch": 5.424120023081362,
      "grad_norm": 0.17528142035007477,
      "learning_rate": 2.2896710905943453e-05,
      "loss": 0.1171,
      "step": 9400
    },
    {
      "epoch": 5.481823427582228,
      "grad_norm": 10.82492733001709,
      "learning_rate": 2.2608193883439124e-05,
      "loss": 0.1004,
      "step": 9500
    },
    {
      "epoch": 5.539526832083093,
      "grad_norm": 0.47684967517852783,
      "learning_rate": 2.2319676860934798e-05,
      "loss": 0.1048,
      "step": 9600
    },
    {
      "epoch": 5.597230236583958,
      "grad_norm": 8.581367492675781,
      "learning_rate": 2.203115983843047e-05,
      "loss": 0.1122,
      "step": 9700
    },
    {
      "epoch": 5.654933641084824,
      "grad_norm": 6.15794563293457,
      "learning_rate": 2.174264281592614e-05,
      "loss": 0.0847,
      "step": 9800
    },
    {
      "epoch": 5.71263704558569,
      "grad_norm": 0.23771034181118011,
      "learning_rate": 2.1454125793421813e-05,
      "loss": 0.0922,
      "step": 9900
    },
    {
      "epoch": 5.770340450086556,
      "grad_norm": 0.18872667849063873,
      "learning_rate": 2.1165608770917487e-05,
      "loss": 0.0934,
      "step": 10000
    },
    {
      "epoch": 5.8280438545874205,
      "grad_norm": 13.620027542114258,
      "learning_rate": 2.0877091748413158e-05,
      "loss": 0.0613,
      "step": 10100
    },
    {
      "epoch": 5.885747259088286,
      "grad_norm": 0.007885175757110119,
      "learning_rate": 2.058857472590883e-05,
      "loss": 0.1019,
      "step": 10200
    },
    {
      "epoch": 5.943450663589152,
      "grad_norm": 3.913397789001465,
      "learning_rate": 2.0300057703404503e-05,
      "loss": 0.127,
      "step": 10300
    },
    {
      "epoch": 6.0,
      "eval_f1": 0.9571539859776682,
      "eval_loss": 0.19625940918922424,
      "eval_runtime": 11.371,
      "eval_samples_per_second": 270.953,
      "eval_steps_per_second": 16.973,
      "step": 10398
    },
    {
      "epoch": 6.001154068090018,
      "grad_norm": 0.7474250197410583,
      "learning_rate": 2.0011540680900173e-05,
      "loss": 0.0975,
      "step": 10400
    },
    {
      "epoch": 6.058857472590883,
      "grad_norm": 1.1747320890426636,
      "learning_rate": 1.9723023658395844e-05,
      "loss": 0.0695,
      "step": 10500
    },
    {
      "epoch": 6.116560877091748,
      "grad_norm": 3.401071786880493,
      "learning_rate": 1.943739180611656e-05,
      "loss": 0.0875,
      "step": 10600
    },
    {
      "epoch": 6.174264281592614,
      "grad_norm": 0.26190730929374695,
      "learning_rate": 1.9148874783612234e-05,
      "loss": 0.0878,
      "step": 10700
    },
    {
      "epoch": 6.23196768609348,
      "grad_norm": 0.09199588745832443,
      "learning_rate": 1.8860357761107905e-05,
      "loss": 0.068,
      "step": 10800
    },
    {
      "epoch": 6.289671090594345,
      "grad_norm": 0.332970529794693,
      "learning_rate": 1.857184073860358e-05,
      "loss": 0.0711,
      "step": 10900
    },
    {
      "epoch": 6.3473744950952105,
      "grad_norm": 3.7900595664978027,
      "learning_rate": 1.8283323716099253e-05,
      "loss": 0.0703,
      "step": 11000
    },
    {
      "epoch": 6.405077899596076,
      "grad_norm": 0.021992277354002,
      "learning_rate": 1.7994806693594923e-05,
      "loss": 0.0703,
      "step": 11100
    },
    {
      "epoch": 6.462781304096942,
      "grad_norm": 0.09862420707941055,
      "learning_rate": 1.7706289671090594e-05,
      "loss": 0.0507,
      "step": 11200
    },
    {
      "epoch": 6.520484708597808,
      "grad_norm": 3.817751884460449,
      "learning_rate": 1.7417772648586268e-05,
      "loss": 0.0739,
      "step": 11300
    },
    {
      "epoch": 6.578188113098673,
      "grad_norm": 0.28442034125328064,
      "learning_rate": 1.712925562608194e-05,
      "loss": 0.0809,
      "step": 11400
    },
    {
      "epoch": 6.635891517599538,
      "grad_norm": 9.373058319091797,
      "learning_rate": 1.6840738603577613e-05,
      "loss": 0.0651,
      "step": 11500
    },
    {
      "epoch": 6.693594922100404,
      "grad_norm": 14.043447494506836,
      "learning_rate": 1.6552221581073284e-05,
      "loss": 0.0797,
      "step": 11600
    },
    {
      "epoch": 6.75129832660127,
      "grad_norm": 2.4154279232025146,
      "learning_rate": 1.6263704558568958e-05,
      "loss": 0.0736,
      "step": 11700
    },
    {
      "epoch": 6.809001731102135,
      "grad_norm": 6.057408809661865,
      "learning_rate": 1.5975187536064628e-05,
      "loss": 0.0851,
      "step": 11800
    },
    {
      "epoch": 6.866705135603,
      "grad_norm": 9.025028228759766,
      "learning_rate": 1.56866705135603e-05,
      "loss": 0.075,
      "step": 11900
    },
    {
      "epoch": 6.924408540103866,
      "grad_norm": 0.8304752111434937,
      "learning_rate": 1.5398153491055973e-05,
      "loss": 0.0529,
      "step": 12000
    },
    {
      "epoch": 6.982111944604732,
      "grad_norm": 10.229031562805176,
      "learning_rate": 1.5109636468551644e-05,
      "loss": 0.0812,
      "step": 12100
    },
    {
      "epoch": 7.0,
      "eval_f1": 0.9528054535920294,
      "eval_loss": 0.26672834157943726,
      "eval_runtime": 11.3573,
      "eval_samples_per_second": 271.279,
      "eval_steps_per_second": 16.993,
      "step": 12131
    },
    {
      "epoch": 7.039815349105597,
      "grad_norm": 0.06422963738441467,
      "learning_rate": 1.4821119446047318e-05,
      "loss": 0.085,
      "step": 12200
    },
    {
      "epoch": 7.097518753606463,
      "grad_norm": 0.48716962337493896,
      "learning_rate": 1.453260242354299e-05,
      "loss": 0.0664,
      "step": 12300
    },
    {
      "epoch": 7.155222158107328,
      "grad_norm": 8.18791389465332,
      "learning_rate": 1.4244085401038662e-05,
      "loss": 0.053,
      "step": 12400
    },
    {
      "epoch": 7.212925562608194,
      "grad_norm": 2.673250198364258,
      "learning_rate": 1.3955568378534333e-05,
      "loss": 0.0683,
      "step": 12500
    },
    {
      "epoch": 7.27062896710906,
      "grad_norm": 11.13698959350586,
      "learning_rate": 1.3667051356030005e-05,
      "loss": 0.0653,
      "step": 12600
    },
    {
      "epoch": 7.328332371609925,
      "grad_norm": 5.246968746185303,
      "learning_rate": 1.3378534333525678e-05,
      "loss": 0.0795,
      "step": 12700
    },
    {
      "epoch": 7.38603577611079,
      "grad_norm": 0.039542973041534424,
      "learning_rate": 1.3092902481246394e-05,
      "loss": 0.0756,
      "step": 12800
    },
    {
      "epoch": 7.443739180611656,
      "grad_norm": 0.07867493480443954,
      "learning_rate": 1.2804385458742066e-05,
      "loss": 0.0575,
      "step": 12900
    },
    {
      "epoch": 7.501442585112522,
      "grad_norm": 9.721111297607422,
      "learning_rate": 1.2515868436237737e-05,
      "loss": 0.0756,
      "step": 13000
    },
    {
      "epoch": 7.559145989613388,
      "grad_norm": 0.004337233491241932,
      "learning_rate": 1.2227351413733411e-05,
      "loss": 0.0586,
      "step": 13100
    },
    {
      "epoch": 7.6168493941142525,
      "grad_norm": 6.687386989593506,
      "learning_rate": 1.1938834391229083e-05,
      "loss": 0.0576,
      "step": 13200
    },
    {
      "epoch": 7.674552798615118,
      "grad_norm": 3.398732900619507,
      "learning_rate": 1.1650317368724756e-05,
      "loss": 0.0728,
      "step": 13300
    },
    {
      "epoch": 7.732256203115984,
      "grad_norm": 0.09737713634967804,
      "learning_rate": 1.1361800346220428e-05,
      "loss": 0.0687,
      "step": 13400
    },
    {
      "epoch": 7.789959607616849,
      "grad_norm": 11.268471717834473,
      "learning_rate": 1.1073283323716099e-05,
      "loss": 0.064,
      "step": 13500
    },
    {
      "epoch": 7.847663012117715,
      "grad_norm": 6.878231525421143,
      "learning_rate": 1.0784766301211773e-05,
      "loss": 0.0721,
      "step": 13600
    },
    {
      "epoch": 7.90536641661858,
      "grad_norm": 16.258480072021484,
      "learning_rate": 1.0496249278707445e-05,
      "loss": 0.0616,
      "step": 13700
    },
    {
      "epoch": 7.963069821119446,
      "grad_norm": 8.84567928314209,
      "learning_rate": 1.0207732256203116e-05,
      "loss": 0.0339,
      "step": 13800
    },
    {
      "epoch": 8.0,
      "eval_f1": 0.9574247144340602,
      "eval_loss": 0.27284932136535645,
      "eval_runtime": 11.358,
      "eval_samples_per_second": 271.263,
      "eval_steps_per_second": 16.992,
      "step": 13864
    },
    {
      "epoch": 8.020773225620312,
      "grad_norm": 0.16235724091529846,
      "learning_rate": 9.91921523369879e-06,
      "loss": 0.0572,
      "step": 13900
    },
    {
      "epoch": 8.078476630121177,
      "grad_norm": 0.282564252614975,
      "learning_rate": 9.63069821119446e-06,
      "loss": 0.0651,
      "step": 14000
    },
    {
      "epoch": 8.136180034622043,
      "grad_norm": 0.857842743396759,
      "learning_rate": 9.342181188690133e-06,
      "loss": 0.0554,
      "step": 14100
    },
    {
      "epoch": 8.193883439122908,
      "grad_norm": 0.7368373870849609,
      "learning_rate": 9.053664166185805e-06,
      "loss": 0.0401,
      "step": 14200
    },
    {
      "epoch": 8.251586843623773,
      "grad_norm": 0.21970252692699432,
      "learning_rate": 8.765147143681478e-06,
      "loss": 0.0694,
      "step": 14300
    },
    {
      "epoch": 8.30929024812464,
      "grad_norm": 2.853633165359497,
      "learning_rate": 8.47663012117715e-06,
      "loss": 0.0477,
      "step": 14400
    },
    {
      "epoch": 8.366993652625505,
      "grad_norm": 0.013686534948647022,
      "learning_rate": 8.188113098672822e-06,
      "loss": 0.0552,
      "step": 14500
    },
    {
      "epoch": 8.424697057126371,
      "grad_norm": 5.044261932373047,
      "learning_rate": 7.899596076168495e-06,
      "loss": 0.0552,
      "step": 14600
    },
    {
      "epoch": 8.482400461627236,
      "grad_norm": 0.4369966685771942,
      "learning_rate": 7.611079053664166e-06,
      "loss": 0.0428,
      "step": 14700
    },
    {
      "epoch": 8.540103866128101,
      "grad_norm": 1.0222536325454712,
      "learning_rate": 7.322562031159839e-06,
      "loss": 0.0381,
      "step": 14800
    },
    {
      "epoch": 8.597807270628968,
      "grad_norm": 2.888136386871338,
      "learning_rate": 7.036930178880555e-06,
      "loss": 0.0549,
      "step": 14900
    },
    {
      "epoch": 8.655510675129833,
      "grad_norm": 0.003512590192258358,
      "learning_rate": 6.748413156376226e-06,
      "loss": 0.0731,
      "step": 15000
    },
    {
      "epoch": 8.713214079630697,
      "grad_norm": 0.5785322785377502,
      "learning_rate": 6.4598961338718985e-06,
      "loss": 0.0468,
      "step": 15100
    },
    {
      "epoch": 8.770917484131564,
      "grad_norm": 2.744781970977783,
      "learning_rate": 6.171379111367571e-06,
      "loss": 0.0701,
      "step": 15200
    },
    {
      "epoch": 8.828620888632429,
      "grad_norm": 10.481842994689941,
      "learning_rate": 5.882862088863243e-06,
      "loss": 0.0609,
      "step": 15300
    },
    {
      "epoch": 8.886324293133296,
      "grad_norm": 2.13496994972229,
      "learning_rate": 5.5943450663589156e-06,
      "loss": 0.0337,
      "step": 15400
    },
    {
      "epoch": 8.94402769763416,
      "grad_norm": 1.3325377702713013,
      "learning_rate": 5.305828043854588e-06,
      "loss": 0.058,
      "step": 15500
    },
    {
      "epoch": 9.0,
      "eval_f1": 0.9562062710546775,
      "eval_loss": 0.28995436429977417,
      "eval_runtime": 11.3831,
      "eval_samples_per_second": 270.665,
      "eval_steps_per_second": 16.955,
      "step": 15597
    },
    {
      "epoch": 9.001731102135025,
      "grad_norm": 0.24910110235214233,
      "learning_rate": 5.01731102135026e-06,
      "loss": 0.0464,
      "step": 15600
    },
    {
      "epoch": 9.059434506635892,
      "grad_norm": 0.043737418949604034,
      "learning_rate": 4.728793998845933e-06,
      "loss": 0.0307,
      "step": 15700
    },
    {
      "epoch": 9.117137911136757,
      "grad_norm": 0.04821854829788208,
      "learning_rate": 4.440276976341604e-06,
      "loss": 0.0479,
      "step": 15800
    },
    {
      "epoch": 9.174841315637623,
      "grad_norm": 14.205366134643555,
      "learning_rate": 4.1517599538372765e-06,
      "loss": 0.0394,
      "step": 15900
    },
    {
      "epoch": 9.232544720138488,
      "grad_norm": 1.5494178533554077,
      "learning_rate": 3.863242931332949e-06,
      "loss": 0.043,
      "step": 16000
    },
    {
      "epoch": 9.290248124639353,
      "grad_norm": 0.9727516174316406,
      "learning_rate": 3.574725908828621e-06,
      "loss": 0.0734,
      "step": 16100
    },
    {
      "epoch": 9.34795152914022,
      "grad_norm": 0.3591306507587433,
      "learning_rate": 3.2862088863242936e-06,
      "loss": 0.0572,
      "step": 16200
    },
    {
      "epoch": 9.405654933641085,
      "grad_norm": 2.838064432144165,
      "learning_rate": 2.9976918638199655e-06,
      "loss": 0.0437,
      "step": 16300
    },
    {
      "epoch": 9.463358338141951,
      "grad_norm": 0.012857385911047459,
      "learning_rate": 2.709174841315638e-06,
      "loss": 0.0368,
      "step": 16400
    },
    {
      "epoch": 9.521061742642816,
      "grad_norm": 2.3932580947875977,
      "learning_rate": 2.42065781881131e-06,
      "loss": 0.0482,
      "step": 16500
    },
    {
      "epoch": 9.578765147143681,
      "grad_norm": 0.008263546042144299,
      "learning_rate": 2.132140796306982e-06,
      "loss": 0.0458,
      "step": 16600
    },
    {
      "epoch": 9.636468551644548,
      "grad_norm": 11.899913787841797,
      "learning_rate": 1.8436237738026545e-06,
      "loss": 0.0493,
      "step": 16700
    },
    {
      "epoch": 9.694171956145412,
      "grad_norm": 0.04145381972193718,
      "learning_rate": 1.5551067512983267e-06,
      "loss": 0.0349,
      "step": 16800
    },
    {
      "epoch": 9.751875360646277,
      "grad_norm": 16.320058822631836,
      "learning_rate": 1.2665897287939988e-06,
      "loss": 0.0511,
      "step": 16900
    },
    {
      "epoch": 9.809578765147144,
      "grad_norm": 22.307905197143555,
      "learning_rate": 9.780727062896712e-07,
      "loss": 0.0447,
      "step": 17000
    },
    {
      "epoch": 9.867282169648009,
      "grad_norm": 0.015102457255125046,
      "learning_rate": 6.895556837853433e-07,
      "loss": 0.0383,
      "step": 17100
    },
    {
      "epoch": 9.924985574148876,
      "grad_norm": 6.079780101776123,
      "learning_rate": 4.0392383150605884e-07,
      "loss": 0.0445,
      "step": 17200
    },
    {
      "epoch": 9.98268897864974,
      "grad_norm": 0.5450202226638794,
      "learning_rate": 1.154068090017311e-07,
      "loss": 0.0453,
      "step": 17300
    },
    {
      "epoch": 10.0,
      "eval_f1": 0.9569725246241574,
      "eval_loss": 0.2978953719139099,
      "eval_runtime": 11.4358,
      "eval_samples_per_second": 269.416,
      "eval_steps_per_second": 16.877,
      "step": 17330
    }
  ],
  "logging_steps": 100,
  "max_steps": 17330,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.82355694693632e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
