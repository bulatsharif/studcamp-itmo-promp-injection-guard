{
  "best_global_step": 8056,
  "best_metric": 0.20389702916145325,
  "best_model_checkpoint": "/kaggle/working/results/checkpoint-8056",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 8056,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04965243296921549,
      "grad_norm": 0.7495262622833252,
      "learning_rate": 4.975670307845084e-05,
      "loss": 0.1135,
      "step": 100
    },
    {
      "epoch": 0.09930486593843098,
      "grad_norm": 5.899048805236816,
      "learning_rate": 4.950844091360477e-05,
      "loss": 0.1046,
      "step": 200
    },
    {
      "epoch": 0.14895729890764647,
      "grad_norm": 3.330947160720825,
      "learning_rate": 4.926017874875869e-05,
      "loss": 0.1089,
      "step": 300
    },
    {
      "epoch": 0.19860973187686196,
      "grad_norm": 8.928207397460938,
      "learning_rate": 4.901191658391261e-05,
      "loss": 0.1065,
      "step": 400
    },
    {
      "epoch": 0.24826216484607747,
      "grad_norm": 0.03291414678096771,
      "learning_rate": 4.876365441906653e-05,
      "loss": 0.0893,
      "step": 500
    },
    {
      "epoch": 0.29791459781529295,
      "grad_norm": 0.012129798531532288,
      "learning_rate": 4.851787487586892e-05,
      "loss": 0.0994,
      "step": 600
    },
    {
      "epoch": 0.34756703078450846,
      "grad_norm": 0.30330902338027954,
      "learning_rate": 4.826961271102284e-05,
      "loss": 0.0974,
      "step": 700
    },
    {
      "epoch": 0.3972194637537239,
      "grad_norm": 0.4556984007358551,
      "learning_rate": 4.802135054617676e-05,
      "loss": 0.0926,
      "step": 800
    },
    {
      "epoch": 0.4468718967229394,
      "grad_norm": 1.4471012353897095,
      "learning_rate": 4.777308838133069e-05,
      "loss": 0.0937,
      "step": 900
    },
    {
      "epoch": 0.49652432969215493,
      "grad_norm": 1.5098974704742432,
      "learning_rate": 4.752482621648461e-05,
      "loss": 0.1135,
      "step": 1000
    },
    {
      "epoch": 0.5461767626613704,
      "grad_norm": 14.936245918273926,
      "learning_rate": 4.727656405163853e-05,
      "loss": 0.1008,
      "step": 1100
    },
    {
      "epoch": 0.5958291956305859,
      "grad_norm": 5.824963092803955,
      "learning_rate": 4.702830188679245e-05,
      "loss": 0.1112,
      "step": 1200
    },
    {
      "epoch": 0.6454816285998014,
      "grad_norm": 1.8059576749801636,
      "learning_rate": 4.678003972194638e-05,
      "loss": 0.1187,
      "step": 1300
    },
    {
      "epoch": 0.6951340615690169,
      "grad_norm": 2.3453831672668457,
      "learning_rate": 4.6531777557100296e-05,
      "loss": 0.1116,
      "step": 1400
    },
    {
      "epoch": 0.7447864945382324,
      "grad_norm": 6.639450550079346,
      "learning_rate": 4.628351539225422e-05,
      "loss": 0.1131,
      "step": 1500
    },
    {
      "epoch": 0.7944389275074478,
      "grad_norm": 8.444064140319824,
      "learning_rate": 4.603525322740814e-05,
      "loss": 0.091,
      "step": 1600
    },
    {
      "epoch": 0.8440913604766633,
      "grad_norm": 13.455053329467773,
      "learning_rate": 4.5786991062562066e-05,
      "loss": 0.129,
      "step": 1700
    },
    {
      "epoch": 0.8937437934458788,
      "grad_norm": 1.767443060874939,
      "learning_rate": 4.5538728897715985e-05,
      "loss": 0.1092,
      "step": 1800
    },
    {
      "epoch": 0.9433962264150944,
      "grad_norm": 1.4517433643341064,
      "learning_rate": 4.529046673286991e-05,
      "loss": 0.1112,
      "step": 1900
    },
    {
      "epoch": 0.9930486593843099,
      "grad_norm": 0.24268881976604462,
      "learning_rate": 4.5042204568023836e-05,
      "loss": 0.1087,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9394024015638089,
      "eval_f1": 0.9457364341085271,
      "eval_loss": 0.22262194752693176,
      "eval_precision": 0.9188532555879495,
      "eval_recall": 0.9742400824317362,
      "eval_runtime": 13.3184,
      "eval_samples_per_second": 268.877,
      "eval_steps_per_second": 16.819,
      "step": 2014
    },
    {
      "epoch": 1.0427010923535254,
      "grad_norm": 9.297073364257812,
      "learning_rate": 4.4793942403177755e-05,
      "loss": 0.0685,
      "step": 2100
    },
    {
      "epoch": 1.0923535253227408,
      "grad_norm": 0.008375275880098343,
      "learning_rate": 4.454568023833168e-05,
      "loss": 0.0775,
      "step": 2200
    },
    {
      "epoch": 1.1420059582919564,
      "grad_norm": 2.098811149597168,
      "learning_rate": 4.42974180734856e-05,
      "loss": 0.0756,
      "step": 2300
    },
    {
      "epoch": 1.1916583912611718,
      "grad_norm": 4.928688049316406,
      "learning_rate": 4.4049155908639526e-05,
      "loss": 0.0903,
      "step": 2400
    },
    {
      "epoch": 1.2413108242303874,
      "grad_norm": 0.4965020418167114,
      "learning_rate": 4.3800893743793445e-05,
      "loss": 0.0796,
      "step": 2500
    },
    {
      "epoch": 1.2909632571996028,
      "grad_norm": 0.06535948067903519,
      "learning_rate": 4.355263157894737e-05,
      "loss": 0.088,
      "step": 2600
    },
    {
      "epoch": 1.3406156901688182,
      "grad_norm": 0.0021369399037212133,
      "learning_rate": 4.330436941410129e-05,
      "loss": 0.0531,
      "step": 2700
    },
    {
      "epoch": 1.3902681231380338,
      "grad_norm": 15.9901123046875,
      "learning_rate": 4.3058589870903675e-05,
      "loss": 0.107,
      "step": 2800
    },
    {
      "epoch": 1.4399205561072492,
      "grad_norm": 0.06383546441793442,
      "learning_rate": 4.28103277060576e-05,
      "loss": 0.0712,
      "step": 2900
    },
    {
      "epoch": 1.4895729890764646,
      "grad_norm": 0.07925543934106827,
      "learning_rate": 4.256206554121152e-05,
      "loss": 0.0761,
      "step": 3000
    },
    {
      "epoch": 1.5392254220456802,
      "grad_norm": 9.791168212890625,
      "learning_rate": 4.2313803376365446e-05,
      "loss": 0.0775,
      "step": 3100
    },
    {
      "epoch": 1.5888778550148959,
      "grad_norm": 4.158282279968262,
      "learning_rate": 4.2065541211519365e-05,
      "loss": 0.0698,
      "step": 3200
    },
    {
      "epoch": 1.6385302879841113,
      "grad_norm": 10.349196434020996,
      "learning_rate": 4.181727904667329e-05,
      "loss": 0.0882,
      "step": 3300
    },
    {
      "epoch": 1.6881827209533267,
      "grad_norm": 10.345704078674316,
      "learning_rate": 4.156901688182721e-05,
      "loss": 0.0655,
      "step": 3400
    },
    {
      "epoch": 1.7378351539225423,
      "grad_norm": 0.2545270025730133,
      "learning_rate": 4.1320754716981135e-05,
      "loss": 0.0738,
      "step": 3500
    },
    {
      "epoch": 1.7874875868917577,
      "grad_norm": 0.016633672639727592,
      "learning_rate": 4.1072492552135054e-05,
      "loss": 0.0692,
      "step": 3600
    },
    {
      "epoch": 1.837140019860973,
      "grad_norm": 5.598625183105469,
      "learning_rate": 4.082423038728898e-05,
      "loss": 0.0507,
      "step": 3700
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.01108716893941164,
      "learning_rate": 4.05759682224429e-05,
      "loss": 0.0855,
      "step": 3800
    },
    {
      "epoch": 1.9364448857994043,
      "grad_norm": 0.09583134949207306,
      "learning_rate": 4.0327706057596824e-05,
      "loss": 0.071,
      "step": 3900
    },
    {
      "epoch": 1.9860973187686195,
      "grad_norm": 13.491856575012207,
      "learning_rate": 4.007944389275074e-05,
      "loss": 0.0619,
      "step": 4000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9472214465233175,
      "eval_f1": 0.9515508843886183,
      "eval_loss": 0.24886417388916016,
      "eval_precision": 0.9469387755102041,
      "eval_recall": 0.9562081401339516,
      "eval_runtime": 13.2731,
      "eval_samples_per_second": 269.794,
      "eval_steps_per_second": 16.876,
      "step": 4028
    },
    {
      "epoch": 2.035749751737835,
      "grad_norm": 10.468917846679688,
      "learning_rate": 3.983118172790467e-05,
      "loss": 0.0536,
      "step": 4100
    },
    {
      "epoch": 2.0854021847070507,
      "grad_norm": 0.017575060948729515,
      "learning_rate": 3.958291956305859e-05,
      "loss": 0.0693,
      "step": 4200
    },
    {
      "epoch": 2.135054617676266,
      "grad_norm": 0.021128760650753975,
      "learning_rate": 3.933465739821251e-05,
      "loss": 0.0523,
      "step": 4300
    },
    {
      "epoch": 2.1847070506454815,
      "grad_norm": 0.005279845092445612,
      "learning_rate": 3.908639523336643e-05,
      "loss": 0.0679,
      "step": 4400
    },
    {
      "epoch": 2.234359483614697,
      "grad_norm": 3.845585584640503,
      "learning_rate": 3.883813306852036e-05,
      "loss": 0.0583,
      "step": 4500
    },
    {
      "epoch": 2.284011916583913,
      "grad_norm": 0.9613376259803772,
      "learning_rate": 3.858987090367428e-05,
      "loss": 0.0632,
      "step": 4600
    },
    {
      "epoch": 2.333664349553128,
      "grad_norm": 1.0123019218444824,
      "learning_rate": 3.83416087388282e-05,
      "loss": 0.0515,
      "step": 4700
    },
    {
      "epoch": 2.3833167825223436,
      "grad_norm": Infinity,
      "learning_rate": 3.809334657398213e-05,
      "loss": 0.0441,
      "step": 4800
    },
    {
      "epoch": 2.432969215491559,
      "grad_norm": 0.025629855692386627,
      "learning_rate": 3.784756703078451e-05,
      "loss": 0.0657,
      "step": 4900
    },
    {
      "epoch": 2.482621648460775,
      "grad_norm": 0.05138208717107773,
      "learning_rate": 3.759930486593843e-05,
      "loss": 0.0479,
      "step": 5000
    },
    {
      "epoch": 2.53227408142999,
      "grad_norm": 0.45626330375671387,
      "learning_rate": 3.735104270109235e-05,
      "loss": 0.047,
      "step": 5100
    },
    {
      "epoch": 2.5819265143992056,
      "grad_norm": 6.91273832321167,
      "learning_rate": 3.710278053624628e-05,
      "loss": 0.0666,
      "step": 5200
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 1.0353132486343384,
      "learning_rate": 3.68545183714002e-05,
      "loss": 0.0776,
      "step": 5300
    },
    {
      "epoch": 2.6812313803376364,
      "grad_norm": 16.933128356933594,
      "learning_rate": 3.660625620655412e-05,
      "loss": 0.0604,
      "step": 5400
    },
    {
      "epoch": 2.730883813306852,
      "grad_norm": 0.07158778607845306,
      "learning_rate": 3.635799404170804e-05,
      "loss": 0.0755,
      "step": 5500
    },
    {
      "epoch": 2.7805362462760677,
      "grad_norm": 4.802702903747559,
      "learning_rate": 3.610973187686197e-05,
      "loss": 0.0547,
      "step": 5600
    },
    {
      "epoch": 2.830188679245283,
      "grad_norm": 0.412356972694397,
      "learning_rate": 3.5861469712015886e-05,
      "loss": 0.0296,
      "step": 5700
    },
    {
      "epoch": 2.8798411122144985,
      "grad_norm": 0.007036637980490923,
      "learning_rate": 3.561320754716981e-05,
      "loss": 0.0822,
      "step": 5800
    },
    {
      "epoch": 2.929493545183714,
      "grad_norm": 0.10073311626911163,
      "learning_rate": 3.536494538232373e-05,
      "loss": 0.0575,
      "step": 5900
    },
    {
      "epoch": 2.9791459781529293,
      "grad_norm": 11.002371788024902,
      "learning_rate": 3.5116683217477656e-05,
      "loss": 0.0436,
      "step": 6000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9480592013404077,
      "eval_f1": 0.9528875379939209,
      "eval_loss": 0.25819504261016846,
      "eval_precision": 0.9372197309417041,
      "eval_recall": 0.9690880989180835,
      "eval_runtime": 13.266,
      "eval_samples_per_second": 269.938,
      "eval_steps_per_second": 16.885,
      "step": 6042
    },
    {
      "epoch": 3.028798411122145,
      "grad_norm": 0.4567073881626129,
      "learning_rate": 3.4868421052631575e-05,
      "loss": 0.111,
      "step": 6100
    },
    {
      "epoch": 3.0784508440913605,
      "grad_norm": 0.07533181458711624,
      "learning_rate": 3.46201588877855e-05,
      "loss": 0.0816,
      "step": 6200
    },
    {
      "epoch": 3.128103277060576,
      "grad_norm": 12.791166305541992,
      "learning_rate": 3.4371896722939427e-05,
      "loss": 0.1104,
      "step": 6300
    },
    {
      "epoch": 3.1777557100297913,
      "grad_norm": 5.583100318908691,
      "learning_rate": 3.4123634558093345e-05,
      "loss": 0.112,
      "step": 6400
    },
    {
      "epoch": 3.227408142999007,
      "grad_norm": 16.0927677154541,
      "learning_rate": 3.387537239324727e-05,
      "loss": 0.0978,
      "step": 6500
    },
    {
      "epoch": 3.2770605759682225,
      "grad_norm": 0.3378296196460724,
      "learning_rate": 3.362711022840119e-05,
      "loss": 0.1214,
      "step": 6600
    },
    {
      "epoch": 3.326713008937438,
      "grad_norm": 4.357152938842773,
      "learning_rate": 3.3378848063555116e-05,
      "loss": 0.1243,
      "step": 6700
    },
    {
      "epoch": 3.3763654419066533,
      "grad_norm": 0.41261008381843567,
      "learning_rate": 3.3130585898709035e-05,
      "loss": 0.1113,
      "step": 6800
    },
    {
      "epoch": 3.426017874875869,
      "grad_norm": 6.952317237854004,
      "learning_rate": 3.288232373386296e-05,
      "loss": 0.0758,
      "step": 6900
    },
    {
      "epoch": 3.4756703078450846,
      "grad_norm": 0.06451095640659332,
      "learning_rate": 3.2634061569016886e-05,
      "loss": 0.1015,
      "step": 7000
    },
    {
      "epoch": 3.5253227408142997,
      "grad_norm": 11.614097595214844,
      "learning_rate": 3.2388282025819265e-05,
      "loss": 0.0917,
      "step": 7100
    },
    {
      "epoch": 3.5749751737835154,
      "grad_norm": 3.1565001010894775,
      "learning_rate": 3.214001986097319e-05,
      "loss": 0.1005,
      "step": 7200
    },
    {
      "epoch": 3.624627606752731,
      "grad_norm": 0.31060436367988586,
      "learning_rate": 3.189175769612711e-05,
      "loss": 0.1067,
      "step": 7300
    },
    {
      "epoch": 3.674280039721946,
      "grad_norm": 6.9694132804870605,
      "learning_rate": 3.1643495531281036e-05,
      "loss": 0.0901,
      "step": 7400
    },
    {
      "epoch": 3.723932472691162,
      "grad_norm": 1.4418213367462158,
      "learning_rate": 3.1395233366434955e-05,
      "loss": 0.0817,
      "step": 7500
    },
    {
      "epoch": 3.7735849056603774,
      "grad_norm": 1.606606125831604,
      "learning_rate": 3.114697120158888e-05,
      "loss": 0.0677,
      "step": 7600
    },
    {
      "epoch": 3.8232373386295926,
      "grad_norm": 0.030315380543470383,
      "learning_rate": 3.08987090367428e-05,
      "loss": 0.0713,
      "step": 7700
    },
    {
      "epoch": 3.872889771598808,
      "grad_norm": 0.05630485713481903,
      "learning_rate": 3.0650446871896725e-05,
      "loss": 0.0997,
      "step": 7800
    },
    {
      "epoch": 3.922542204568024,
      "grad_norm": 3.5044937133789062,
      "learning_rate": 3.0402184707050647e-05,
      "loss": 0.0953,
      "step": 7900
    },
    {
      "epoch": 3.9721946375372394,
      "grad_norm": 17.897659301757812,
      "learning_rate": 3.0153922542204573e-05,
      "loss": 0.0841,
      "step": 8000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9505724657916783,
      "eval_f1": 0.9542753810384913,
      "eval_loss": 0.20389702916145325,
      "eval_precision": 0.9569948186528497,
      "eval_recall": 0.9515713549716641,
      "eval_runtime": 13.2507,
      "eval_samples_per_second": 270.25,
      "eval_steps_per_second": 16.905,
      "step": 8056
    }
  ],
  "logging_steps": 100,
  "max_steps": 20140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8478490647920640.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
